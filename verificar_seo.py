#!/usr/bin/env python
"""
Script para verificar a implementa√ß√£o SEO dos artigos
Executa valida√ß√µes b√°sicas de SEO on-page
"""

import os
import sys
import django
from bs4 import BeautifulSoup

# Configurar Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'setup.settings')
django.setup()

from artigos.models import Artigo
from django.test import Client
from django.urls import reverse

def verificar_seo_artigo(artigo):
    """
    Verifica elementos SEO de um artigo espec√≠fico
    """
    print(f"\nüîç Verificando SEO: {artigo.titulo}")
    print("=" * 60)
    
    # Usar Django test client
    client = Client()
    response = client.get(artigo.get_absolute_url())
    
    if response.status_code != 200:
        print(f"‚ùå Erro: Status {response.status_code}")
        return
    
    # Parse HTML
    soup = BeautifulSoup(response.content, 'html.parser')
    
    seo_score = 0
    max_score = 15
    
    # 1. Verificar t√≠tulo H1
    h1 = soup.find('h1')
    if h1 and h1.get_text().strip():
        print("‚úÖ H1 encontrado:", h1.get_text()[:50] + "...")
        seo_score += 1
    else:
        print("‚ùå H1 n√£o encontrado ou vazio")
    
    # 2. Verificar meta description
    meta_desc = soup.find('meta', attrs={'name': 'description'})
    if meta_desc and meta_desc.get('content'):
        desc = meta_desc.get('content')
        print(f"‚úÖ Meta description ({len(desc)} chars):", desc[:80] + "...")
        if 120 <= len(desc) <= 160:
            seo_score += 1
        else:
            print(f"‚ö†Ô∏è  Meta description deveria ter 120-160 chars (atual: {len(desc)})")
    else:
        print("‚ùå Meta description n√£o encontrada")
    
    # 3. Verificar meta keywords
    meta_keywords = soup.find('meta', attrs={'name': 'keywords'})
    if meta_keywords and meta_keywords.get('content'):
        print("‚úÖ Meta keywords:", meta_keywords.get('content')[:50] + "...")
        seo_score += 1
    else:
        print("‚ùå Meta keywords n√£o encontradas")
    
    # 4. Verificar canonical URL
    canonical = soup.find('link', attrs={'rel': 'canonical'})
    if canonical and canonical.get('href'):
        print("‚úÖ URL can√¥nica:", canonical.get('href'))
        seo_score += 1
    else:
        print("‚ùå URL can√¥nica n√£o encontrada")
    
    # 5. Verificar Open Graph
    og_title = soup.find('meta', attrs={'property': 'og:title'})
    og_desc = soup.find('meta', attrs={'property': 'og:description'})
    og_image = soup.find('meta', attrs={'property': 'og:image'})
    
    og_count = 0
    if og_title:
        print("‚úÖ OG Title:", og_title.get('content', '')[:50] + "...")
        og_count += 1
    if og_desc:
        print("‚úÖ OG Description:", og_desc.get('content', '')[:50] + "...")
        og_count += 1
    if og_image:
        print("‚úÖ OG Image:", og_image.get('content', '')[:50] + "...")
        og_count += 1
    
    if og_count >= 2:
        seo_score += 1
    
    # 6. Verificar Twitter Cards
    twitter_card = soup.find('meta', attrs={'name': 'twitter:card'})
    if twitter_card:
        print("‚úÖ Twitter Card:", twitter_card.get('content'))
        seo_score += 1
    else:
        print("‚ùå Twitter Card n√£o encontrada")
    
    # 7. Verificar JSON-LD Schema
    json_ld = soup.find('script', attrs={'type': 'application/ld+json'})
    if json_ld:
        print("‚úÖ Schema.org JSON-LD encontrado")
        seo_score += 1
    else:
        print("‚ùå Schema.org JSON-LD n√£o encontrado")
    
    # 8. Verificar estrutura de cabe√ßalhos
    headings = {
        'h1': len(soup.find_all('h1')),
        'h2': len(soup.find_all('h2')),
        'h3': len(soup.find_all('h3')),
        'h4': len(soup.find_all('h4')),
    }
    
    if headings['h1'] == 1:
        print("‚úÖ Exatamente 1 H1 encontrado")
        seo_score += 1
    else:
        print(f"‚ùå N√∫mero incorreto de H1: {headings['h1']} (deveria ser 1)")
    
    if headings['h2'] >= 1:
        print(f"‚úÖ {headings['h2']} cabe√ßalhos H2 encontrados")
        seo_score += 1
    else:
        print("‚ö†Ô∏è  Nenhum H2 encontrado - considere adicionar subt√≠tulos")
    
    # 9. Verificar imagens com alt
    images = soup.find_all('img')
    images_with_alt = [img for img in images if img.get('alt')]
    
    if images:
        alt_percentage = (len(images_with_alt) / len(images)) * 100
        print(f"üì∑ Imagens: {len(images)} total, {len(images_with_alt)} com alt ({alt_percentage:.1f}%)")
        if alt_percentage >= 90:
            seo_score += 1
    else:
        print("‚ö†Ô∏è  Nenhuma imagem encontrada")
        seo_score += 1  # N√£o penalizar se n√£o h√° imagens
    
    # 10. Verificar links internos
    internal_links = soup.find_all('a', href=True)
    blog_links = [link for link in internal_links if '/blog/' in link.get('href', '')]
    
    if len(blog_links) >= 2:
        print(f"‚úÖ {len(blog_links)} links internos para blog encontrados")
        seo_score += 1
    else:
        print(f"‚ö†Ô∏è  Poucos links internos: {len(blog_links)} (recomendado: 2+)")
    
    # 11. Verificar breadcrumbs
    breadcrumbs = soup.find('nav', attrs={'aria-label': 'Breadcrumb'})
    if breadcrumbs:
        print("‚úÖ Breadcrumbs encontrados")
        seo_score += 1
    else:
        print("‚ùå Breadcrumbs n√£o encontrados")
    
    # 12. Verificar tempo de leitura
    reading_time = soup.find(text=lambda text: text and 'min de leitura' in text)
    if reading_time:
        print("‚úÖ Tempo de leitura exibido")
        seo_score += 1
    else:
        print("‚ùå Tempo de leitura n√£o encontrado")
    
    # 13. Verificar bot√µes de compartilhamento
    share_buttons = soup.find_all('a', href=lambda x: x and ('facebook.com' in x or 'twitter.com' in x or 'linkedin.com' in x))
    if len(share_buttons) >= 3:
        print(f"‚úÖ {len(share_buttons)} bot√µes de compartilhamento encontrados")
        seo_score += 1
    else:
        print(f"‚ö†Ô∏è  Poucos bot√µes de compartilhamento: {len(share_buttons)}")
    
    # 14. Verificar artigos relacionados
    related_section = soup.find(text=lambda text: text and 'Relacionados' in text)
    if related_section:
        print("‚úÖ Se√ß√£o de artigos relacionados encontrada")
        seo_score += 1
    else:
        print("‚ùå Artigos relacionados n√£o encontrados")
    
    # 15. Verificar responsividade (meta viewport)
    viewport = soup.find('meta', attrs={'name': 'viewport'})
    if viewport:
        print("‚úÖ Meta viewport configurado")
        seo_score += 1
    else:
        print("‚ùå Meta viewport n√£o encontrado")
    
    # Resultado final
    percentage = (seo_score / max_score) * 100
    print(f"\nüìä SCORE SEO: {seo_score}/{max_score} ({percentage:.1f}%)")
    
    if percentage >= 90:
        print("üéâ EXCELENTE! SEO altamente otimizado")
    elif percentage >= 70:
        print("üëç BOM! SEO bem configurado com algumas melhorias poss√≠veis")
    elif percentage >= 50:
        print("‚ö†Ô∏è  REGULAR! V√°rias melhorias SEO necess√°rias")
    else:
        print("‚ùå CR√çTICO! SEO precisa de aten√ß√£o urgente")
    
    return seo_score, max_score

def verificar_sitemap():
    """
    Verifica se o sitemap est√° funcionando
    """
    print("\nüó∫Ô∏è  Verificando Sitemap...")
    client = Client()
    
    try:
        response = client.get('/sitemap.xml')
        if response.status_code == 200:
            print("‚úÖ Sitemap.xml acess√≠vel")
            # Parse XML
            soup = BeautifulSoup(response.content, 'xml')
            urls = soup.find_all('url')
            print(f"‚úÖ {len(urls)} URLs no sitemap")
            return True
        else:
            print(f"‚ùå Erro no sitemap: Status {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Erro ao acessar sitemap: {e}")
        return False

def verificar_robots():
    """
    Verifica robots.txt
    """
    print("\nü§ñ Verificando Robots.txt...")
    client = Client()
    
    try:
        response = client.get('/robots.txt')
        if response.status_code == 200:
            print("‚úÖ Robots.txt acess√≠vel")
            content = response.content.decode('utf-8')
            if 'Sitemap:' in content:
                print("‚úÖ Sitemap referenciado no robots.txt")
                return True
            else:
                print("‚ö†Ô∏è  Sitemap n√£o referenciado no robots.txt")
                return False
        else:
            print(f"‚ùå Erro no robots.txt: Status {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Erro ao acessar robots.txt: {e}")
        return False

def main():
    """
    Fun√ß√£o principal para verificar SEO de todos os artigos
    """
    print("üöÄ VERIFICA√á√ÉO SEO - PRISMA AVALIA√á√ïES")
    print("=" * 60)
    
    # Verificar sitemap e robots
    sitemap_ok = verificar_sitemap()
    robots_ok = verificar_robots()
    
    # Buscar artigos publicados
    artigos = Artigo.objects.filter(publicado=True)[:5]  # Primeiros 5 artigos
    
    if not artigos:
        print("\n‚ùå Nenhum artigo publicado encontrado!")
        return
    
    total_score = 0
    total_max = 0
    
    # Verificar cada artigo
    for artigo in artigos:
        score, max_score = verificar_seo_artigo(artigo)
        total_score += score
        total_max += max_score
    
    # Resultado geral
    print("\n" + "=" * 60)
    print("üìà RELAT√ìRIO GERAL SEO")
    print("=" * 60)
    
    if artigos:
        avg_percentage = (total_score / total_max) * 100
        print(f"üìä Score m√©dio: {total_score}/{total_max} ({avg_percentage:.1f}%)")
        print(f"üìù Artigos verificados: {len(artigos)}")
    
    print(f"üó∫Ô∏è  Sitemap: {'‚úÖ OK' if sitemap_ok else '‚ùå ERRO'}")
    print(f"ü§ñ Robots.txt: {'‚úÖ OK' if robots_ok else '‚ùå ERRO'}")
    
    print("\n‚ú® Verifica√ß√£o conclu√≠da!")
    print("\nPara melhorar o SEO:")
    print("1. Certifique-se de que meta descriptions tenham 120-160 caracteres")
    print("2. Use estrutura hier√°rquica de cabe√ßalhos (H1 > H2 > H3)")
    print("3. Adicione alt text em todas as imagens")
    print("4. Inclua links internos relevantes")
    print("5. Configure palavras-chave estrat√©gicas")

if __name__ == '__main__':
    main()
